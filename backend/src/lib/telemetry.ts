/**
 * src/lib/telemetry.ts
 * --------------------------------------------------------------------------
 * ðŸ§  Enterprise-grade Telemetry & Observability Layer
 *
 * Purpose:
 *  - Unified telemetry for metrics, traces, and logs.
 *  - Integrates seamlessly with Prometheus, OpenTelemetry, Datadog, etc.
 *  - Supports async worker instrumentation and distributed trace correlation.
 *  - Enables unified observability across API + background jobs + AI workers.
 * --------------------------------------------------------------------------
 */

import os from "os";
import { performance } from "perf_hooks";
import { EventEmitter } from "events";
import { context, trace, SpanStatusCode } from "@opentelemetry/api";
import logger from "../logger";
import { config } from "../config";

type MetricType = "counter" | "gauge" | "histogram" | "timer";

interface Metric {
  name: string;
  type: MetricType;
  value: number;
  labels?: Record<string, string>;
  traceId?: string;
  timestamp?: number;
}

/**
 * ðŸš€ Telemetry Core Class
 * Handles metric buffering, trace correlation, and exporter integration.
 */
class Telemetry extends EventEmitter {
  private metrics: Metric[] = [];
  private lastFlush = Date.now();
  private flushInterval: NodeJS.Timeout | null = null;

  constructor() {
    super();
    this.startAutoFlush();
    logger.info(`[telemetry] âœ… Initialized telemetry system for ${config.nodeEnv}`);
  }

  /**
   * Record a single metric event (with optional trace context)
   */
  record(name: string, value: number, type: MetricType = "gauge", labels?: Record<string, string>) {
    const activeSpan = trace.getSpan(context.active());
    const traceId = activeSpan?.spanContext()?.traceId;

    const metric: Metric = {
      name,
      value,
      type,
      labels,
      traceId,
      timestamp: Date.now(),
    };

    this.metrics.push(metric);
  }

  /**
   * Measure and record execution time of async functions.
   * Automatically correlates with active trace span.
   */
  timer<T extends (...args: any[]) => Promise<any>>(name: string, fn: T): T {
    return (async (...args: any[]) => {
      const span = trace.getTracer("telemetry").startSpan(name);
      const start = performance.now();
      try {
        const result = await fn(...args);
        const duration = performance.now() - start;
        this.record(name, duration, "timer");
        span.setStatus({ code: SpanStatusCode.OK });
        span.end();
        return result;
      } catch (err: any) {
        const duration = performance.now() - start;
        this.record(`${name}_error`, duration, "timer");
        span.setStatus({ code: SpanStatusCode.ERROR, message: err.message });
        span.end();
        throw err;
      }
    }) as T;
  }

  /**
   * Collect local system metrics (runtime health snapshot)
   */
  collectSystemMetrics() {
    const cpuLoad = os.loadavg()[0];
    const totalMemMB = os.totalmem() / 1024 / 1024;
    const usedMemMB = process.memoryUsage().rss / 1024 / 1024;
    const uptime = process.uptime();

    this.record("system.cpu.load", Number(cpuLoad.toFixed(2)));
    this.record("system.memory.used.mb", Number(usedMemMB.toFixed(2)));
    this.record("system.memory.total.mb", Number(totalMemMB.toFixed(2)));
    this.record("system.uptime.seconds", uptime);
  }

  /**
   * Auto-flush buffer periodically (safe for long-running workers)
   */
  startAutoFlush(intervalMs = 10000) {
    if (this.flushInterval) clearInterval(this.flushInterval);
    this.flushInterval = setInterval(() => this.flush(), intervalMs);
  }

  /**
   * Flush all metrics to configured exporter or log sink
   */
  flush() {
    if (this.metrics.length === 0) return;

    const now = Date.now();
    const diff = (now - this.lastFlush) / 1000;
    const count = this.metrics.length;

    logger.info(`[telemetry] ðŸ“¤ Flushing ${count} metrics (${diff.toFixed(1)}s since last flush)`);

    try {
      // ðŸš€ Integration points â€” can be swapped based on deployment:
      // Example: send to Prometheus, Datadog, OpenTelemetry Collector, etc.
      if (config.telemetry?.export === "logger") {
        this.metrics.forEach((m) => {
          logger.debug(`[metric] ${m.name}=${m.value}`, { labels: m.labels, traceId: m.traceId });
        });
      } else if (config.telemetry?.export === "collector") {
        // TODO: push to OTLP / gRPC endpoint (e.g., OpenTelemetry Collector)
      }

      this.emit("flush", this.metrics);

      this.metrics = [];
      this.lastFlush = now;
    } catch (err: any) {
      logger.error("[telemetry] âŒ Failed to flush metrics:", err.message);
    }
  }

  /**
   * Shutdown safely (called during process termination)
   */
  async shutdown() {
    if (this.flushInterval) clearInterval(this.flushInterval);
    this.collectSystemMetrics();
    this.flush();
    logger.info("[telemetry] ðŸ§¹ Graceful shutdown complete.");
  }
}

/* --------------------------------------------------------------------------
   ðŸ“¦ Global Telemetry Instance
-------------------------------------------------------------------------- */
export const telemetry = new Telemetry();

/* --------------------------------------------------------------------------
   ðŸ§  Snapshot Helper
-------------------------------------------------------------------------- */
export const telemetrySnapshot = () => ({
  timestamp: new Date().toISOString(),
  cpuLoad: os.loadavg()[0],
  memoryMB: (process.memoryUsage().heapUsed / 1024 / 1024).toFixed(2),
  uptimeSec: process.uptime(),
  pendingMetrics: telemetry.listenerCount("flush"),
  environment: config.nodeEnv,
});

/* --------------------------------------------------------------------------
   ðŸ§© Graceful Shutdown Hooks
-------------------------------------------------------------------------- */
process.on("SIGTERM", async () => await telemetry.shutdown());
process.on("SIGINT", async () => await telemetry.shutdown());