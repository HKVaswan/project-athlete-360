// src/lib/backupClient.ts
/**
 * Backup Client (Enterprise-Grade)
 * ----------------------------------
 *  - Secure PostgreSQL backups using pg_dump
 *  - Local + Cloud (S3) backup pipeline
 *  - AES encryption + SHA256 checksum
 *  - Super Admin notifications on failure/success
 *  - Configurable retention
 */

import fs from "fs";
import path from "path";
import crypto from "crypto";
import { exec } from "child_process";
import { promisify } from "util";
import { logger } from "../logger";
import { config } from "../config";
import { uploadToS3 } from "./s3";
import { addNotificationJob } from "../workers/notification.worker";

const execAsync = promisify(exec);
const BACKUP_DIR = path.join(process.cwd(), "backups");

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
/* ğŸ§± Ensure backup directory exists */
/* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
const ensureBackupDir = () => {
  if (!fs.existsSync(BACKUP_DIR)) {
    fs.mkdirSync(BACKUP_DIR, { recursive: true });
    logger.info(`[BACKUP] ğŸ“ Created directory: ${BACKUP_DIR}`);
  }
};

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
/* ğŸ§® Generate filename + checksum */
/* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
const generateBackupFilename = (prefix = "backup") => {
  const timestamp = new Date().toISOString().replace(/[:.]/g, "-");
  return `${prefix}-${timestamp}.sql`;
};

const generateChecksum = (filePath: string): string => {
  const fileBuffer = fs.readFileSync(filePath);
  const hashSum = crypto.createHash("sha256");
  hashSum.update(fileBuffer);
  return hashSum.digest("hex");
};

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
/* ğŸ” Optional AES-256 encryption   */
/* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
const encryptFile = (inputPath: string, password: string): string => {
  const outputPath = inputPath + ".enc";
  const cipher = crypto.createCipher("aes-256-cbc", password);
  const input = fs.createReadStream(inputPath);
  const output = fs.createWriteStream(outputPath);
  input.pipe(cipher).pipe(output);
  return outputPath;
};

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
/* ğŸ’¾ Create PostgreSQL backup     */
/* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
export const createDatabaseBackup = async (): Promise<string> => {
  ensureBackupDir();
  const backupFile = path.join(BACKUP_DIR, generateBackupFilename("db"));

  try {
    const databaseUrl = config.databaseUrl;
    if (!databaseUrl) throw new Error("Database URL not found");

    // Safer password handling (avoids leaking password via process list)
    const { PGPASSWORD, ...env } = process.env;
    const dbUrl = new URL(databaseUrl);
    const pgPassword = dbUrl.password;
    dbUrl.password = "";

    const cmd = `pg_dump --no-owner --no-privileges -Fc -f "${backupFile}" "${dbUrl.toString()}"`;

    await execAsync(cmd, {
      env: { ...env, PGPASSWORD: pgPassword },
    });

    logger.info(`[BACKUP] âœ… Created backup at ${backupFile}`);
    return backupFile;
  } catch (err: any) {
    logger.error(`[BACKUP] âŒ Database backup failed: ${err.message}`);
    await addNotificationJob({
      type: "criticalAlert",
      title: "Database Backup Failure",
      message: `Backup failed: ${err.message}`,
      severity: "high",
    });
    throw new Error("Database backup failed");
  }
};

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
/* â˜ï¸ Upload backup to S3 securely */
/* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
export const uploadBackupToCloud = async (backupPath: string) => {
  try {
    const encryptionPassword = config.backupEncryptionKey || "default-key";
    const encryptedPath = encryptFile(backupPath, encryptionPassword);

    const checksum = generateChecksum(encryptedPath);
    const fileName = path.basename(encryptedPath);
    const fileStream = fs.createReadStream(encryptedPath);

    const result = await uploadToS3({
      key: `backups/${fileName}`,
      body: fileStream,
      contentType: "application/octet-stream",
      metadata: { checksum },
    });

    logger.info(`[BACKUP] â˜ï¸ Uploaded encrypted backup: ${result.key}`);
    return { ...result, checksum };
  } catch (err: any) {
    logger.error(`[BACKUP] âŒ Cloud upload failed: ${err.message}`);
    await addNotificationJob({
      type: "criticalAlert",
      title: "Backup Upload Failure",
      message: `Cloud upload failed: ${err.message}`,
      severity: "high",
    });
    throw new Error("Cloud backup upload failed");
  }
};

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
/* ğŸ§¹ Clean up old local backups   */
/* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
export const cleanupOldBackups = async (retentionDays = 7) => {
  ensureBackupDir();
  const now = Date.now();
  let deletedCount = 0;

  try {
    const files = fs.readdirSync(BACKUP_DIR);
    for (const file of files) {
      const filePath = path.join(BACKUP_DIR, file);
      const stats = fs.statSync(filePath);
      if (now - stats.mtimeMs > retentionDays * 24 * 60 * 60 * 1000) {
        fs.unlinkSync(filePath);
        deletedCount++;
      }
    }
    if (deletedCount > 0) {
      logger.info(`[BACKUP] ğŸ§¹ Deleted ${deletedCount} old backups`);
      await addNotificationJob({
        type: "info",
        title: "Old Backups Cleaned",
        message: `${deletedCount} old backups deleted after ${retentionDays} days`,
      });
    }
  } catch (err: any) {
    logger.error(`[BACKUP] âš ï¸ Cleanup failed: ${err.message}`);
  }
};

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
/* ğŸª„ Full backup pipeline         */
/* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
export const runFullBackup = async () => {
  logger.info("[BACKUP] ğŸš€ Starting full backup pipeline...");
  try {
    const backupPath = await createDatabaseBackup();
    const cloudResult = await uploadBackupToCloud(backupPath);
    await cleanupOldBackups(7);

    await addNotificationJob({
      type: "info",
      title: "Database Backup Completed",
      message: `Backup uploaded: ${cloudResult.key}\nChecksum: ${cloudResult.checksum}`,
    });

    logger.info("[BACKUP] âœ… Full backup completed successfully.");
  } catch (err: any) {
    logger.error(`[BACKUP] âŒ Full backup failed: ${err.message}`);
    await addNotificationJob({
      type: "criticalAlert",
      title: "Backup Pipeline Failure",
      message: `Full backup failed: ${err.message}`,
      severity: "high",
    });
  }
};